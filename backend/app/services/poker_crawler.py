#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PokerScout ì‹¤ì‹œê°„ í¬ë¡¤ë§ ì‹¤í–‰ ë° ê²°ê³¼ í‘œì‹œ
online_data_collector.pyì™€ ë™ì¼í•œ ë¡œì§ìœ¼ë¡œ ì „ì²´ ì‚¬ì´íŠ¸ í¬ë¡¤ë§
"""

import cloudscraper
from bs4 import BeautifulSoup
import json
from datetime import datetime
import logging
import sys
import re

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class LivePokerScoutCrawler:
    def __init__(self):
        self.scraper = cloudscraper.create_scraper(
            browser={'browser': 'chrome', 'platform': 'linux', 'mobile': False}
        )
        # GG í¬ì»¤ ì‚¬ì´íŠ¸ ì‹ë³„ìš© (online_data_collector.pyì™€ ë™ì¼)
        self.gg_poker_sites = ['GGNetwork', 'GGPoker ON', 'GG Poker', 'GGPoker']
        
    def crawl_pokerscout_data(self):
        """PokerScout í¬ë¡¤ë§ - online_data_collector.pyì™€ ë™ì¼í•œ ë¡œì§"""
        logger.info("PokerScout ì‹¤ì‹œê°„ í¬ë¡¤ë§ ì‹œì‘...")
        
        try:
            # 1. ì›¹ì‚¬ì´íŠ¸ ì ‘ì†
            logger.info("https://www.pokerscout.com ì ‘ì† ì¤‘...")
            response = self.scraper.get('https://www.pokerscout.com', timeout=30)
            response.raise_for_status()
            logger.info(f"ì‘ë‹µ ìƒíƒœ ì½”ë“œ: {response.status_code}")
            
            # 2. HTML íŒŒì‹±
            soup = BeautifulSoup(response.content, 'html.parser')
            table = soup.find('table', {'class': 'rankTable'})
            
            if not table:
                logger.error("PokerScout í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return []
            
            logger.info("rankTable ë°œê²¬!")
            
            # 3. ë°ì´í„° ì¶”ì¶œ
            collected_data = []
            rows = table.find_all('tr')[1:]  # Skip header
            logger.info(f"ë°œê²¬ëœ í–‰ ìˆ˜: {len(rows)}")
            
            for i, row in enumerate(rows):
                try:
                    # CoinPoker ê´‘ê³  í–‰ì€ ê±´ë„ˆë›°ê¸°
                    if 'cus_top_traffic_coin' in row.get('class', []):
                        continue
                    
                    # ì‚¬ì´íŠ¸ëª… ì¶”ì¶œ
                    brand_title = row.find('span', {'class': 'brand-title'})
                    if not brand_title:
                        continue
                    
                    site_name = brand_title.get_text(strip=True)
                    if not site_name or len(site_name) < 2:
                        continue
                    
                    # ê° ë°ì´í„° í•„ë“œë¥¼ IDë¡œ ì§ì ‘ ì°¾ê¸°
                    players_online = 0
                    cash_players = 0
                    peak_24h = 0
                    seven_day_avg = 0
                    
                    # Players Online
                    online_td = row.find('td', {'id': 'online'})
                    if online_td:
                        online_span = online_td.find('span')
                        if online_span:
                            online_text = online_span.get_text(strip=True).replace(',', '')
                            if online_text.isdigit():
                                players_online = int(online_text)
                    
                    # Cash Players
                    cash_td = row.find('td', {'id': 'cash'})
                    if cash_td:
                        cash_text = cash_td.get_text(strip=True).replace(',', '')
                        if cash_text.isdigit():
                            cash_players = int(cash_text)
                    
                    # 24H Peak
                    peak_td = row.find('td', {'id': 'peak'})
                    if peak_td:
                        peak_span = peak_td.find('span')
                        if peak_span:
                            peak_text = peak_span.get_text(strip=True).replace(',', '')
                            if peak_text.isdigit():
                                peak_24h = int(peak_text)
                    
                    # 7 Day Average
                    avg_td = row.find('td', {'id': 'avg'})
                    if avg_td:
                        avg_span = avg_td.find('span')
                        if avg_span:
                            avg_text = avg_span.get_text(strip=True).replace(',', '')
                            if avg_text.isdigit():
                                seven_day_avg = int(avg_text)
                    
                    # ë°ì´í„° ê²€ì¦ - ëª¨ë“  ê°’ì´ 0ì¸ ê²½ìš° ì œì™¸
                    if players_online == 0 and cash_players == 0 and peak_24h == 0:
                        continue
                    
                    # ì‚¬ì´íŠ¸ëª… ì •ê·œí™”
                    site_name = re.sub(r'[^\w\s\-\(\)\.&]', '', site_name).strip()
                    
                    # GG í¬ì»¤ ì—¬ë¶€ í™•ì¸
                    category = 'GG_POKER' if site_name in self.gg_poker_sites else 'COMPETITOR'
                    
                    site_data = {
                        'site_name': site_name,
                        'category': category,
                        'players_online': players_online,
                        'cash_players': cash_players,
                        'peak_24h': peak_24h,
                        'seven_day_avg': seven_day_avg,
                        'collected_at': datetime.now().isoformat()
                    }
                    
                    collected_data.append(site_data)
                    
                except Exception as e:
                    logger.error(f"í–‰ {i+1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    continue
            
            logger.info(f"í¬ë¡¤ë§ ì™„ë£Œ: {len(collected_data)}ê°œ ì‚¬ì´íŠ¸ ìˆ˜ì§‘")
            return collected_data
            
        except Exception as e:
            logger.error(f"í¬ë¡¤ë§ ì‹¤íŒ¨: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
            return []
    
    def analyze_results(self, data):
        """í¬ë¡¤ë§ ê²°ê³¼ ë¶„ì„"""
        if not data:
            logger.error("ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return
        
        logger.info("\n" + "="*60)
        logger.info("í¬ë¡¤ë§ ê²°ê³¼ ë¶„ì„")
        logger.info("="*60)
        
        # ê¸°ë³¸ í†µê³„
        total_sites = len(data)
        gg_sites = [site for site in data if site['category'] == 'GG_POKER']
        competitor_sites = [site for site in data if site['category'] == 'COMPETITOR']
        
        # ì´ í”Œë ˆì´ì–´ ìˆ˜ ê³„ì‚°
        total_players = sum(site['players_online'] for site in data)
        total_cash = sum(site['cash_players'] for site in data)
        
        logger.info(f"ì´ ì‚¬ì´íŠ¸ ìˆ˜: {total_sites}ê°œ")
        logger.info(f"GG í¬ì»¤ ì‚¬ì´íŠ¸: {len(gg_sites)}ê°œ")
        logger.info(f"ê²½ìŸì‚¬ ì‚¬ì´íŠ¸: {len(competitor_sites)}ê°œ")
        logger.info(f"ì´ ì˜¨ë¼ì¸ í”Œë ˆì´ì–´: {total_players:,}ëª…")
        logger.info(f"ì´ ìºì‹œ í”Œë ˆì´ì–´: {total_cash:,}ëª…")
        
        # GG í¬ì»¤ ìƒì„¸ ì •ë³´
        if gg_sites:
            logger.info("GG í¬ì»¤ ì‚¬ì´íŠ¸ ìƒì„¸:")
            for site in gg_sites:
                logger.info(f"   â€¢ {site['site_name']}: {site['players_online']:,}ëª… ì˜¨ë¼ì¸")
        
        # ìƒìœ„ 10ê°œ ì‚¬ì´íŠ¸
        logger.info(f"\nìƒìœ„ 10ê°œ ì‚¬ì´íŠ¸ (í”Œë ˆì´ì–´ ìˆ˜ ê¸°ì¤€):")
        sorted_sites = sorted(data, key=lambda x: x['players_online'], reverse=True)
        
        for i, site in enumerate(sorted_sites[:10]):
            category_icon = "" if site['category'] == 'GG_POKER' else ""
            logger.info(f"{i+1:2d}. {category_icon} {site['site_name']:25s}: {site['players_online']:8,}ëª…")
        
        # ë°ì´í„° ì €ì¥
        result = {
            'crawl_time': datetime.now().isoformat(),
            'total_sites': total_sites,
            'gg_poker_sites': len(gg_sites),
            'competitor_sites': len(competitor_sites),
            'total_players': total_players,
            'total_cash_players': total_cash,
            'sites': data
        }
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        filename = f"live_crawling_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        logger.info(f"\nğŸ’¾ ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        return result

