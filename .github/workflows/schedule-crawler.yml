name: Scheduled PokerScout Crawler

on:
  schedule:
    # 매일 자정 (UTC)에 실행
    - cron: '0 0 * * *'
  workflow_dispatch: # 수동 실행을 허용

permissions:
  contents: write

jobs:
  crawl:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9' # 크롤러에 필요한 Python 버전

      - name: Install dependencies
        run: |
          pip install cloudscraper beautifulsoup4 firebase-admin

      - name: Create Firebase Service Account Key File
        run: |
          mkdir -p backend/key
          echo '${{ secrets.FIREBASE_SERVICE_ACCOUNT_KEY }}' > ./backend/key/firebase-service-account-key.json

      - name: Run PokerScout Crawler
        working-directory: ./backend
        run: python app/services/poker_crawler.py

      - name: Commit and Push JSON Backup
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          
          # data 폴더가 존재하고 JSON 파일이 있는지 확인
          if [ -d "data" ] && [ "$(ls -A data/*.json 2>/dev/null)" ]; then
            git add -f data/*.json
            git commit -m "📊 Add crawling result backup - $(date +'%Y-%m-%d %H:%M:%S UTC')

            🤖 Generated with [Claude Code](https://claude.ai/code)

            Co-Authored-By: Claude <noreply@anthropic.com>"
            git push
            echo "✅ JSON 백업 파일이 성공적으로 커밋되고 푸시되었습니다."
          else
            echo "⚠️ 백업할 JSON 파일을 찾을 수 없습니다."
          fi
        
