name: Enhanced Daily Poker Data Crawl with Alerts

on:
  schedule:
    # ë§¤ì¼ UTC 18:00 (í•œêµ­ì‹œê°„ ì˜¤ì „ 3ì‹œ)ì— ì‹¤í–‰
    - cron: '0 18 * * *'
  workflow_dispatch: # ìˆ˜ë™ ì‹¤í–‰ ê°€ëŠ¥
    inputs:
      debug_mode:
        description: 'Enable debug mode'
        required: false
        default: 'false'

# í•„ìš”í•œ ê¶Œí•œë§Œ ë¶€ì—¬
permissions:
  contents: read
  actions: write      # ì•„í‹°íŒ©íŠ¸ ì—…ë¡œë“œ
  issues: write       # ì‹¤íŒ¨ì‹œ ì´ìŠˆ ìƒì„±

jobs:
  crawl:
    runs-on: ubuntu-latest
    timeout-minutes: 15  # íƒ€ì„ì•„ì›ƒ ì„¤ì •
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.12'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        cd backend
        pip install --upgrade pip
        pip install fastapi firebase-admin cloudscraper beautifulsoup4 lxml requests
        pip install google-auth google-auth-oauthlib google-auth-httplib2
    
    - name: Create Firebase key from secret
      env:
        FIREBASE_KEY: ${{ secrets.FIREBASE_SERVICE_ACCOUNT_KEY }}
      run: |
        mkdir -p backend/key
        echo "$FIREBASE_KEY" > backend/key/firebase-service-account-key.json
    
    - name: Run enhanced crawler with fallback
      id: crawl
      env:
        GITHUB_ACTIONS: true
        DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        ALERT_EMAIL: ${{ secrets.ALERT_EMAIL }}
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        GITHUB_REPO: ${{ github.repository }}
      run: |
        cd backend
        # í–¥ìƒëœ í¬ë¡¤ëŸ¬ ì‹¤í–‰ (í´ë°± ë©”ì»¤ë‹ˆì¦˜ í¬í•¨)
        python enhanced_crawler_with_alert.py || {
          echo "::error::í¬ë¡¤ë§ ì‹¤íŒ¨ - í´ë°± ì‹œë„"
          # ê¸°ì¡´ í¬ë¡¤ëŸ¬ë¡œ í´ë°±
          python github_actions_crawler_firestore.py || {
            echo "::error::ëª¨ë“  í¬ë¡¤ë§ ë°©ë²• ì‹¤íŒ¨"
            exit 1
          }
        }
    
    - name: Check crawl results
      if: always()
      run: |
        cd backend
        # í¬ë¡¤ë§ ê²°ê³¼ íŒŒì¼ í™•ì¸
        if ls crawl_failure_*.json 1> /dev/null 2>&1; then
          echo "::warning::í¬ë¡¤ë§ ì‹¤íŒ¨ ë¦¬í¬íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤"
          cat crawl_failure_*.json
        fi
        
        if ls backup_*.json 1> /dev/null 2>&1; then
          echo "::notice::ë°±ì—… íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤"
        fi
    
    - name: Upload artifacts on failure
      if: failure()
      uses: actions/upload-artifact@v4
      with:
        name: crawl-failure-reports
        path: |
          backend/crawl_failure_*.json
          backend/backup_*.json
          backend/error_screenshot_*.png
        retention-days: 7
    
    - name: Create issue on repeated failures
      if: failure()
      uses: actions/github-script@v6
      with:
        script: |
          const title = `í¬ë¡¤ë§ ì‹¤íŒ¨: ${new Date().toISOString().split('T')[0]}`;
          const body = `
          ## í¬ë¡¤ë§ ì‹¤íŒ¨ ì•Œë¦¼
          
          **ì‹¤í–‰ ì‹œê°„:** ${new Date().toISOString()}
          **ì›Œí¬í”Œë¡œìš°:** ${context.workflow}
          **ì‹¤í–‰ ID:** ${context.runId}
          
          ### ìƒì„¸ ì •ë³´
          - [ì›Œí¬í”Œë¡œìš° ë¡œê·¸ í™•ì¸](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})
          
          ### í™•ì¸ í•„ìš” ì‚¬í•­
          1. PokerScout.com ì ‘ì† ê°€ëŠ¥ ì—¬ë¶€
          2. í˜ì´ì§€ êµ¬ì¡° ë³€ê²½ ì—¬ë¶€
          3. CloudFlare ì°¨ë‹¨ ì—¬ë¶€
          4. Firebase ì—°ê²° ìƒíƒœ
          
          ì´ ì´ìŠˆëŠ” ìë™ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
          `;
          
          // ìµœê·¼ 24ì‹œê°„ ë‚´ ë™ì¼í•œ ì´ìŠˆê°€ ìˆëŠ”ì§€ í™•ì¸
          const issues = await github.rest.issues.listForRepo({
            owner: context.repo.owner,
            repo: context.repo.repo,
            labels: 'crawler-failure',
            state: 'open',
            since: new Date(Date.now() - 24*60*60*1000).toISOString()
          });
          
          if (issues.data.length === 0) {
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: title,
              body: body,
              labels: ['crawler-failure', 'automated']
            });
          }
    
    - name: Send Discord notification on failure
      if: failure() && env.DISCORD_WEBHOOK_URL != ''
      env:
        DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
      run: |
        curl -H "Content-Type: application/json" \
          -d "{
            \"embeds\": [{
              \"title\": \"ğŸš¨ PokerScout í¬ë¡¤ë§ ì‹¤íŒ¨\",
              \"description\": \"ì¼ì¼ í¬ë¡¤ë§ ì‘ì—…ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\",
              \"color\": 15158332,
              \"fields\": [
                {
                  \"name\": \"ì‹¤í–‰ ì‹œê°„\",
                  \"value\": \"$(date -u +%Y-%m-%d' '%H:%M:%S' UTC')\",
                  \"inline\": true
                },
                {
                  \"name\": \"ì›Œí¬í”Œë¡œìš°\",
                  \"value\": \"${{ github.workflow }}\",
                  \"inline\": true
                },
                {
                  \"name\": \"ìƒì„¸ ë¡œê·¸\",
                  \"value\": \"[ì—¬ê¸°ë¥¼ í´ë¦­](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})\",
                  \"inline\": false
                }
              ],
              \"timestamp\": \"$(date -u +%Y-%m-%dT%H:%M:%S.000Z)\"
            }]
          }" \
          $DISCORD_WEBHOOK_URL
    
    - name: Clean up
      if: always()
      run: |
        rm -rf backend/key
        # ì˜¤ë˜ëœ ë°±ì—… íŒŒì¼ ì •ë¦¬ (7ì¼ ì´ìƒ)
        find backend -name "backup_*.json" -mtime +7 -delete 2>/dev/null || true
        find backend -name "crawl_failure_*.json" -mtime +7 -delete 2>/dev/null || true

  # í¬ë¡¤ë§ ìƒíƒœ ëª¨ë‹ˆí„°ë§ Job
  monitor:
    runs-on: ubuntu-latest
    needs: crawl
    if: always()
    
    steps:
    - name: Check crawl job status
      run: |
        if [ "${{ needs.crawl.result }}" == "failure" ]; then
          echo "::error::í¬ë¡¤ë§ Jobì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤"
          echo "CRAWL_STATUS=failed" >> $GITHUB_ENV
        elif [ "${{ needs.crawl.result }}" == "success" ]; then
          echo "::notice::í¬ë¡¤ë§ Jobì´ ì„±ê³µí–ˆìŠµë‹ˆë‹¤"
          echo "CRAWL_STATUS=success" >> $GITHUB_ENV
        else
          echo "::warning::í¬ë¡¤ë§ Job ìƒíƒœ: ${{ needs.crawl.result }}"
          echo "CRAWL_STATUS=${{ needs.crawl.result }}" >> $GITHUB_ENV
        fi
    
    - name: Update status badge
      if: always()
      run: |
        # READMEì— ìƒíƒœ ë°°ì§€ ì—…ë°ì´íŠ¸ (ì„ íƒì )
        echo "í¬ë¡¤ë§ ìƒíƒœ: ${{ env.CRAWL_STATUS }}"