name: Enhanced Daily Poker Data Crawl with Alerts

on:
  schedule:
    # 매일 UTC 18:00 (한국시간 오전 3시)에 실행
    - cron: '0 18 * * *'
  workflow_dispatch: # 수동 실행 가능
    inputs:
      debug_mode:
        description: 'Enable debug mode'
        required: false
        default: 'false'

# 필요한 권한만 부여
permissions:
  contents: read
  actions: write      # 아티팩트 업로드
  issues: write       # 실패시 이슈 생성

jobs:
  crawl:
    runs-on: ubuntu-latest
    timeout-minutes: 15  # 타임아웃 설정
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.12'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        cd backend
        pip install --upgrade pip
        pip install fastapi firebase-admin cloudscraper beautifulsoup4 lxml requests
        pip install google-auth google-auth-oauthlib google-auth-httplib2
    
    - name: Create Firebase key from secret
      env:
        FIREBASE_KEY: ${{ secrets.FIREBASE_SERVICE_ACCOUNT_KEY }}
      run: |
        mkdir -p backend/key
        echo "$FIREBASE_KEY" > backend/key/firebase-service-account-key.json
    
    - name: Run enhanced crawler with fallback
      id: crawl
      env:
        GITHUB_ACTIONS: true
        DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        ALERT_EMAIL: ${{ secrets.ALERT_EMAIL }}
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        GITHUB_REPO: ${{ github.repository }}
      run: |
        cd backend
        # 향상된 크롤러 실행 (폴백 메커니즘 포함)
        python enhanced_crawler_with_alert.py || {
          echo "::error::크롤링 실패 - 폴백 시도"
          # 기존 크롤러로 폴백
          python github_actions_crawler_firestore.py || {
            echo "::error::모든 크롤링 방법 실패"
            exit 1
          }
        }
    
    - name: Check crawl results
      if: always()
      run: |
        cd backend
        # 크롤링 결과 파일 확인
        if ls crawl_failure_*.json 1> /dev/null 2>&1; then
          echo "::warning::크롤링 실패 리포트가 생성되었습니다"
          cat crawl_failure_*.json
        fi
        
        if ls backup_*.json 1> /dev/null 2>&1; then
          echo "::notice::백업 파일이 생성되었습니다"
        fi
    
    - name: Upload artifacts on failure
      if: failure()
      uses: actions/upload-artifact@v4
      with:
        name: crawl-failure-reports
        path: |
          backend/crawl_failure_*.json
          backend/backup_*.json
          backend/error_screenshot_*.png
        retention-days: 7
    
    - name: Create issue on repeated failures
      if: failure()
      uses: actions/github-script@v6
      with:
        script: |
          const title = `크롤링 실패: ${new Date().toISOString().split('T')[0]}`;
          const body = `
          ## 크롤링 실패 알림
          
          **실행 시간:** ${new Date().toISOString()}
          **워크플로우:** ${context.workflow}
          **실행 ID:** ${context.runId}
          
          ### 상세 정보
          - [워크플로우 로그 확인](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})
          
          ### 확인 필요 사항
          1. PokerScout.com 접속 가능 여부
          2. 페이지 구조 변경 여부
          3. CloudFlare 차단 여부
          4. Firebase 연결 상태
          
          이 이슈는 자동으로 생성되었습니다.
          `;
          
          // 최근 24시간 내 동일한 이슈가 있는지 확인
          const issues = await github.rest.issues.listForRepo({
            owner: context.repo.owner,
            repo: context.repo.repo,
            labels: 'crawler-failure',
            state: 'open',
            since: new Date(Date.now() - 24*60*60*1000).toISOString()
          });
          
          if (issues.data.length === 0) {
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: title,
              body: body,
              labels: ['crawler-failure', 'automated']
            });
          }
    
    - name: Send Discord notification on failure
      if: failure() && env.DISCORD_WEBHOOK_URL != ''
      env:
        DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
      run: |
        curl -H "Content-Type: application/json" \
          -d "{
            \"embeds\": [{
              \"title\": \"🚨 PokerScout 크롤링 실패\",
              \"description\": \"일일 크롤링 작업이 실패했습니다.\",
              \"color\": 15158332,
              \"fields\": [
                {
                  \"name\": \"실행 시간\",
                  \"value\": \"$(date -u +%Y-%m-%d' '%H:%M:%S' UTC')\",
                  \"inline\": true
                },
                {
                  \"name\": \"워크플로우\",
                  \"value\": \"${{ github.workflow }}\",
                  \"inline\": true
                },
                {
                  \"name\": \"상세 로그\",
                  \"value\": \"[여기를 클릭](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})\",
                  \"inline\": false
                }
              ],
              \"timestamp\": \"$(date -u +%Y-%m-%dT%H:%M:%S.000Z)\"
            }]
          }" \
          $DISCORD_WEBHOOK_URL
    
    - name: Clean up
      if: always()
      run: |
        rm -rf backend/key
        # 오래된 백업 파일 정리 (7일 이상)
        find backend -name "backup_*.json" -mtime +7 -delete 2>/dev/null || true
        find backend -name "crawl_failure_*.json" -mtime +7 -delete 2>/dev/null || true

  # 크롤링 상태 모니터링 Job
  monitor:
    runs-on: ubuntu-latest
    needs: crawl
    if: always()
    
    steps:
    - name: Check crawl job status
      run: |
        if [ "${{ needs.crawl.result }}" == "failure" ]; then
          echo "::error::크롤링 Job이 실패했습니다"
          echo "CRAWL_STATUS=failed" >> $GITHUB_ENV
        elif [ "${{ needs.crawl.result }}" == "success" ]; then
          echo "::notice::크롤링 Job이 성공했습니다"
          echo "CRAWL_STATUS=success" >> $GITHUB_ENV
        else
          echo "::warning::크롤링 Job 상태: ${{ needs.crawl.result }}"
          echo "CRAWL_STATUS=${{ needs.crawl.result }}" >> $GITHUB_ENV
        fi
    
    - name: Update status badge
      if: always()
      run: |
        # README에 상태 배지 업데이트 (선택적)
        echo "크롤링 상태: ${{ env.CRAWL_STATUS }}"